{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8364202-a753-4e7b-9a10-f25380c86527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings, HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI, Cohere\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic\n",
    "from langchain import PromptTemplate\n",
    "#\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time,sleep\n",
    "import openai\n",
    "import tiktoken\n",
    "#\n",
    "import os\n",
    "import json\n",
    "#\n",
    "import io\n",
    "#\n",
    "import mlflow\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20365fa0-f4fb-45b0-a043-f438f8f6f5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Openai key: ········\n",
      "Enter Anthropic key: ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "os.environ['OPENAI_API_KEY'] = getpass(\"Enter Openai key:\")\n",
    "os.environ['ANTHROPIC_API_KEY'] = getpass(\"Enter Anthropic key:\")\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/mnt/data/RAG-mktg/model_cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45145ca5-a76c-4f27-840c-74a2ed52c667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='/mnt/code/data/disease_components.csv',source_column=\"link\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6212dc5-6711-4f48-b2ff-1cc5f59b7c63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold embeddings with model names as keys\n",
    "embeddings_dict = {}\n",
    "\n",
    "metadatas = []\n",
    "texts = []\n",
    "for row in data:\n",
    "  metadatas.append(row.metadata)\n",
    "  texts.append(row.page_content)\n",
    "print(len(metadatas),len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0db99fb-22c0-46a4-9f5f-cc165044ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question enclosed within  3 backticks at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Please provide an answer which is factually correct and based on the information retrieved from the vector store.\n",
    "Please also mention any quotes supporting the answer if any present in the context supplied within two double quotes \"\" .\n",
    "\n",
    "{context}\n",
    "\n",
    "QUESTION:```{question}```\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "#\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff7022b-abd2-4fc9-9e20-484ead4582fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load model based on name\n",
    "def get_qa_chain(llm_name, embedding_model_name='OpenAI'):\n",
    "    \n",
    "    qa = None\n",
    "    doc_store = embeddings_dict.get(embedding_model_name)\n",
    "    \n",
    "    if llm_name == 'Anthropic':\n",
    "        rag_llm = ChatAnthropic(temperature=0,\n",
    "                         anthropic_api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "        \n",
    "    elif llm_name =='gpt-4':\n",
    "        rag_llm = ChatOpenAI(model_name='gpt-4',\n",
    "                             openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "                             temperature=0)\n",
    "        \n",
    "    else:\n",
    "        rag_llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k',\n",
    "                             openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "                             temperature=0)\n",
    "            \n",
    "    return RetrievalQA.from_chain_type(llm=rag_llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                       retriever=doc_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                       return_source_documents=True\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bfa402-8090-4967-b17f-6c0cd07157ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_embedding(embedding_model_name='HuggingFace'):\n",
    "    \n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    \n",
    "    if embedding_model_name == 'OpenAI':\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "           \n",
    "    elif embedding_model_name =='BGE':\n",
    "        embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en\",\n",
    "                                      model_kwargs=model_kwargs,\n",
    "                                      encode_kwargs=encode_kwargs\n",
    "                                     )\n",
    "    else:\n",
    "         embeddings = HuggingFaceEmbeddings(model_kwargs = model_kwargs,\n",
    "                                            encode_kwargs = encode_kwargs,\n",
    "                                           )\n",
    "        \n",
    "    store = Qdrant.from_texts(texts,\n",
    "                              metadatas=metadatas,\n",
    "                              embedding=embeddings,\n",
    "                              location=\":memory:\",\n",
    "                              prefer_grpc=True,\n",
    "                              collection=f\"{embedding_model_name}_medical_qa_search\")\n",
    "    \n",
    "    embeddings_dict[embedding_model_name] = store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec9cd44-61ad-478d-86d9-6a7c7b6bb109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your search params\n",
    "llms = ('OpenAI', 'Anthropic')  # Model names\n",
    "# embedding_models = ('HuggingFace', 'OpenAI', 'BGE')  # Embedding names\n",
    "embedding_models = ('HuggingFace', 'BGE')  # Embedding names\n",
    "# embedding_models = ('BGE')  # Embedding names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58369f7e-8a78-4300-bbf1-ffdad457d4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}  # Dictionary to hold the Qdrant stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ebaa89-fb97-4010-8fc0-0833b6df1953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for HuggingFace\n",
      "Generating embeddings for BGE\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings\n",
    "for model_name in embedding_models:\n",
    "    print(f\"Generating embeddings for {model_name}\")\n",
    "    compute_embedding(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6403ee56-1330-4328-b8c5-4f9d680c375f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'I have persistent back pain since 4 weeks,I workout but havent had any sports injury.What might be the cause of the back pain?', 'ground_truths': ['From the symptoms mentioned you might have a disloacted disk']}, {'query': 'I have shortness of breath and frequently feel nauseated and tired.What can be the possible cause?', 'ground_truths': ['You might have asthama.']}, {'query': 'My 12 year old son has Poor coordination Unsteady walk and a tendency to stumble while walking and poor coordination between two hands.What might be the possible cuase?', 'ground_truths': [' Movement and coordination problems associated with cerebral palsy.Please consult a doctor for better diagnosis.']}, {'query': 'What is Baby acne ?', 'ground_truths': [\"Baby acne is small, inflamed bumps on a baby's face, neck, back or chest.\"]}, {'query': 'What is Botulism ?', 'ground_truths': ['Botulism is a rare and potentially fatal illness caused by a toxin produced by the bacterium Clostridium botulinum.']}]\n"
     ]
    }
   ],
   "source": [
    "#In order to evaluate the qa system we generated a few relevant questions and answers\n",
    "eval_questions = [\n",
    "    \"I have persistent back pain since 4 weeks,I workout but havent had any sports injury.What might be the cause of the back pain?\",\n",
    "    \"I have shortness of breath and frequently feel nauseated and tired.What can be the possible cause?\",\n",
    "    \"My 12 year old son has Poor coordination Unsteady walk and a tendency to stumble while walking and poor coordination between two hands.What might be the possible cuase?\",\n",
    "    \"What is Baby acne ?\",\n",
    "    \"What is Botulism ?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"From the symptoms mentioned you might have a disloacted disk\",  # incorrect answer\n",
    "    \"You might have asthama.\",  # incorrect answer\n",
    "    \" Movement and coordination problems associated with cerebral palsy.Please consult a doctor for better diagnosis.\",\n",
    "    \"Baby acne is small, inflamed bumps on a baby's face, neck, back or chest.\",\n",
    "    \"Botulism is a rare and potentially fatal illness caused by a toxin produced by the bacterium Clostridium botulinum.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truths\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)]\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "223b74ed-6ab8-4c08-8f2b-89f1ec13ab7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create all the evaluation chains\n",
    "from ragas.langchain.evalchain import RagasEvaluatorChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from ragas.llms import LangchainLLM\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\", openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "gpt4_wrapper = LangchainLLM(llm=gpt4)\n",
    "\n",
    "faithfulness.llm = gpt4_wrapper\n",
    "answer_relevancy.llm = gpt4_wrapper\n",
    "context_relevancy.llm = gpt4_wrapper\n",
    "context_recall.llm = gpt4_wrapper\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain = RagasEvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain = RagasEvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain = RagasEvaluatorChain(metric=context_relevancy)\n",
    "context_recall_chain = RagasEvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cca1b6de-581d-4f42-887b-0886cbf60657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OpenAI', 'HuggingFace'),\n",
       " ('OpenAI', 'BGE'),\n",
       " ('Anthropic', 'HuggingFace'),\n",
       " ('Anthropic', 'BGE')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate all combinations of these parameters\n",
    "search_space = list(itertools.product(llms, embedding_models))\n",
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5015a710-0cbb-4b7a-95ac-e46fec4054b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_experiment(model_name, embedding_name):\n",
    "    \n",
    "    qa_chain = get_qa_chain(model_name, embedding_name)\n",
    "    \n",
    "    predictions = qa_chain.batch(examples)\n",
    "    faithfulness_scores = faithfulness_chain.evaluate(examples, predictions)\n",
    "    context_recall_scores = context_recall_chain.evaluate(examples, predictions)\n",
    "    answer_rel_scores = answer_rel_chain.evaluate(examples, predictions)\n",
    "    context_rel_scores = context_rel_chain.evaluate(examples, predictions)\n",
    "    \n",
    "    # Combine scores into a dataframe\n",
    "    df_scores = pd.DataFrame({\n",
    "        'faithfulness': faithfulness_scores,\n",
    "        'context_recall': context_recall_scores,\n",
    "        'answer_relevance': answer_rel_scores,\n",
    "        'context_relevance': context_rel_scores\n",
    "    })\n",
    "    \n",
    "    # Calculate the median of each column\n",
    "    median_scores = df_scores.median().to_dict()\n",
    "    \n",
    "    # Return the results of the experiment \n",
    "    return median_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab4561-efc0-4fb1-8d18-9dc95fe140d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and set the experiment name\n",
    "experiment_name = \"RAG_Parameter_search\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Iterate through each combination and execute the MLflow runs\n",
    "for llm_name, embedding_model_name in search_space:\n",
    "    run_name = f\"{llm_name}_{embedding_model_name}_run\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model\", llm_name)\n",
    "        mlflow.log_param(\"embedding\", embedding_model_name)\n",
    "\n",
    "        # Run the experiment\n",
    "        results = run_experiment(llm_name, embedding_model_name)\n",
    "\n",
    "        # Log results\n",
    "        for key, value in results.items():\n",
    "            mlflow.log_metric(key, value)\n",
    "\n",
    "        # End the run\n",
    "        mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
